<!doctype html><html lang=en-us>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<title> On Dispatch Chains - Matthew Alp </title>
<meta name=HandheldFriendly content="True">
<meta name=MobileOptimized content="320">
<meta name=referrer content="no-referrer">
<meta name=description content="I infrequently write about code.">
<meta property="og:site_name" content="Matthew Alp">
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:url" content="https://mattalp.com/blog/dispatch-chains/">
<meta property="og:title" content="On Dispatch Chains">
<meta property="og:image" content="https://mattalp.com">
<meta property="og:description" content="I infrequently write about code.">
<meta name=twitter:card content="summary_large_image">
<meta name=twitter:title content="On Dispatch Chains">
<meta name=twitter:description content="I infrequently write about code.">
<meta name=twitter:image content="https://mattalp.com">
<link rel=canonical href=https://mattalp.com/blog/dispatch-chains/>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.5.2/css/bootstrap.min.css integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin=anonymous>
<link rel=stylesheet href=https://mattalp.comcss/custom.css>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github-gist.min.css integrity="sha512-od7JLoOTxM8w/HSKGzP9Kexc20K9p/M2zxSWsd7H1e4Ctf+8SQFtCWEZnW5u6ul5ehSECa5QmOk9ju2nQMmlVA==" crossorigin=anonymous>
<link rel="shortcut icon" href=https://mattalp.comimages/favicon.png>
<link href=https://mattalp.com/index.xml rel=alternate type=application/rss+xml title="Matthew Alp">
</head>
<body>
<div class="mt-xl header">
<div class=container>
<div class="row justify-content-center">
<div class=col-auto>
<a href=https://mattalp.com>
<h1 class=name>Matt Alp</h1>
</a>
</div>
</div>
<div class="row justify-content-center">
<ul class="nav nav-primary">
<li class=nav-item>
<a class=nav-link href=../../>
Home
</a>
</li>
<li class=nav-item>
<a class=nav-link href=../../about/>
About
</a>
</li>
</ul>
</div>
</div>
</div>
<div class=content>
<div class=container>
<div class="row justify-content-center">
<div class="col-sm-12 col-lg-8">
<h1 class="mx-0 mx-md-4 blog-post-title">On Dispatch Chains</h1>
<div class="mb-md-4 meta">
<span class=author title="Matthew Alp">
Matthew Alp
</span>
<span class="date middot" title="Thu Jul 21 2022 10:53:09 -0400">
2022-07-21
</span>
<span class="reading-time middot">
8 min read
</span>
<div class="d-none d-md-inline tags">
<ul class="list-unstyled d-inline">
</ul>
</div>
</div>
<div class="markdown blog-post-content">
<h2 id=intro>Intro</h2>
<p>In Ruby, practically everything is an object- an instance of a class containing some data, interacting through sending or receiving messages (via method calls). Unlike statically typed languages, wherein one knows at compile time what the set of messages an object can respond to (i.e. what methods are defined on a class), Ruby provides an extensive suite of ways of extending and modifying this set at run time.</p>
<p>As a consequence of this paradigm, Ruby must look up the method instructions you wish to invoke every time that you request to call a method by name, which is a costly operation involving traversing the object’s ancestry to ascertain if and where the method itself can be executed from. In the interest of performance, this process is sped up by caching the results of these lookups and removing the need for redundant work.</p>
<p>In most implementations of Ruby, this is done via inline caching. Historically, this is done in CRuby/MRI through the use of a “global method state (number)” and a “class serial number”. As shown in Aaron Patterson&rsquo;s <a href=https://tenderlovemaking.com/2015/12/23/inline-caching-in-mri.html>article on in inline caching in MRI</a>, the global method state is a global serial number that gets incremented whenever class definitions are mutated. The class serial number is a number derived from the class of whichever object is receiving a method call at a specific call site. This can be illustrated by running the following Ruby code (before Ruby 3+, as things work a little differently there):</p>
<pre tabindex=0><code>p RubyVM.stat

module Kernel
  def monkey_patched_method
  end
end

p RubyVM.stat
# Notice that global_method_state is incremented at this point

class A
end

p RubyVM.stat
# Class serial will have increased once by now

class B
end

p RubyVM.stat
# Class serial will have increased twice by now
</code></pre><p>We should see something like</p>
<pre tabindex=0><code>{:global_method_state=&gt;133, :global_constant_state=&gt;904, :class_serial=&gt;6329}
{:global_method_state=&gt;134, :global_constant_state=&gt;904, :class_serial=&gt;6329}
{:global_method_state=&gt;134, :global_constant_state=&gt;905, :class_serial=&gt;6331}
{:global_method_state=&gt;134, :global_constant_state=&gt;906, :class_serial=&gt;6333}
</code></pre><p>Furthermore, Aaron points out that in CRuby (&lt;3.1) the cache is rather limited, storing exactly one key-value pair per <em>call site</em> (code invocation location), and then proceeds to present several situations which are failed by the existing caching mechanism. We see that even when a change to a class is small and localized, the change to global method state and class serials could blow out unrelated caches and slow down performance.</p>
<h2 id=polymorphic-inline-caches--dispatch-chains>Polymorphic Inline Caches & Dispatch Chains</h2>
<p>This is where <a href=https://en.wikipedia.org/wiki/Inline_caching>(polymorphic) inline caches</a> and <a href=https://chrisseaton.com/truffleruby/pldi15-metaprogramming/pldi15-marr-et-al-zero-overhead-metaprogramming.pdf>dispatch chaining</a> come in.</p>
<p>Let&rsquo;s start with an inline cache; a small cache included <em>inline</em> (traditionally alongside a call site for a method) that removes the need for redundant method lookup work.</p>
<video preload=auto width=100% autoplay loop muted playsinline class=html-video>
<source src=../../blog/dispatch-chains/Inline-Cache.mp4 type=video/mp4>
<span>Your browser doesn't support embedded videos, but don't worry, you can <a href=../../blog/dispatch-chains/Inline-Cache.mp4>download it</a> and watch it with your favorite video player!</span>
</video>
<p>The cache described above could be described as monomorphic; it fares best when dealing with call sites that only see one (mono) type used, rather than some small number n > 1 (a polymorphic site) or such a large number of variations that it wouldn&rsquo;t be reasonable to cache and look up entries (a megamorphic site).</p>
<p>A polymorphic inline cache expands on this by supporting matching on multiple keys (where key is a like a class or name, or <em>generalized</em> to a set of properties such as class <em>and</em> name) to yield multiple call sites.</p>
<video preload=auto width=100% autoplay loop muted playsinline class=html-video>
<source src=../../blog/dispatch-chains/Poly-Inline-Cache.mp4 type=video/mp4>
<span>Your browser doesn't support embedded videos, but don't worry, you can <a href=../../blog/dispatch-chains/Poly-Inline-Cache.mp4>download it</a> and watch it with your favorite video player!</span>
</video>
<p>A dispatch chain further expands this model of caching & guarding on complex operations by constructing a tree of polymorphic inline caches so that advanced dispatch decisions can be made, in order to support Ruby&rsquo;s complex object model and expressive metaprogramming system. For example, a <code>send</code> can have a tree that first dispatches on</p>
<ul>
<li>the method name,</li>
<li>then on the class,</li>
<li>then on the bytecode or machine code that represents the returned method, in order to execute code.</li>
</ul>
<video preload=auto width=100% autoplay loop muted playsinline class=html-video>
<source src=../../blog/dispatch-chains/Dispatch-Chain-Sideways-tree.mp4 type=video/mp4>
<span>Your browser doesn't support embedded videos, but don't worry, you can <a href=../../blog/dispatch-chains/Dispatch-Chain-Sideways-tree.mp4>download it</a> and watch it with your favorite video player!</span>
</video>
<p>However, a notable downside of said tree model is that memory use from constructing caches can quickly expand as the tree gets wider and wider at subsequent levels of branching decisions.</p>
<p>TruffleRuby further develops on this idea by constructing a series of decision trees, with the output of each (polymorphic cache) going as input to the next. This means that if one decision tree produces the same value from multiple branches, the next decision tree sees them as the same value, instead of having a new copy of the tree (and all potential decisions cascading from that point) for the repeated values.</p>
<video preload=auto width=100% autoplay loop muted playsinline class=html-video>
<source src=../../blog/dispatch-chains/Dispatch-Chain-Sideways-tree-with-duplicates.mp4 type=video/mp4>
<span>Your browser doesn't support embedded videos, but don't worry, you can <a href=../../blog/dispatch-chains/Dispatch-Chain-Sideways-tree-with-duplicates.mp4>download it</a> and watch it with your favorite video player!</span>
</video>
<p>This is particularly useful because it means that we aren&rsquo;t as afraid to add more levels of decision trees and granular caches as memory use isn&rsquo;t expected to increase exponentially. As a result, rather than having one PIC responsible for the caching of a complex process (such as method invocation), a dispatch chain is made up of several PICs with separate concerns and unique cache keys. This both improves the likelihood of breaking down a previously mega/poly site to a poly/mono site and mitigates the consequences of having a megamorphic site&rsquo;s cache blowout cascade through the entire chain of operations being performed.</p>
<p>Let&rsquo;s explore how the use of dispatch chains speeds up method invocation in TruffleRuby, a high-speed JIT-compiled Ruby on top of the GraalVM and the Truffle DSL.</p>
<h2 id=trufflerubys-method-invocation-mechanism>TruffleRuby’s Method Invocation Mechanism</h2>
<blockquote>
<p>First, a quick disclaimer; TruffleRuby makes heavy use of indirection and abstraction within its codebase, which can detract from the exploratory process and overwhelm readers. I’ve simplified and hand-waved away details that aren’t pertinent, but have linked to the source code for the curious.</p>
</blockquote>
<p>Let&rsquo;s kick off the method invocation pipeline via</p>
<pre tabindex=0><code># Object o
o.send :foo_method
o.foo_method
</code></pre><p>This will kick off the method invocation process via a <a href=https://github.com/oracle/truffleruby/blob/e2f62b89b80cf1d9334dca4d31ef8e379a8712c5/src/main/java/org/truffleruby/core/basicobject/BasicObjectNodes.java#L584-L595>SendNode</a>, which defers to several other nodes for supporting functionality. Like all Truffle DSL languages, TruffleRuby uses nodes and an AST for its intermediate representation.</p>
<p>Within the send node, we defer to an instantiated-and-stored <a href=https://github.com/oracle/truffleruby/blob/f9ab0cf8b658bdb6b8a68880556c0b072a2e11a1/src/main/java/org/truffleruby/language/dispatch/DispatchNode.java>DispatchNode</a> responsible for handling lookup and subsequent execution from a call site effectively.</p>
<pre tabindex=0><code>protected DispatchNode(
        MetaClassNode metaclassNode,
        LookupMethodNode methodLookup,
        CallInternalMethodNode callNode) {
    this.metaclassNode = metaclassNode;
    this.methodLookup = methodLookup;
    this.callNode = callNode;
}
</code></pre><p>Among other things, the dispatch node contains a <a href=https://github.com/oracle/truffleruby/blob/75d3da3737ff43c906086aaaf349b09360b10bda/src/main/java/org/truffleruby/language/methods/LookupMethodNode.java>LookupMethodNode</a> and <a href=https://github.com/oracle/truffleruby/blob/83e0079d6f9edc96a252a59d794cd1b6af8d7ca3/src/main/java/org/truffleruby/language/methods/CallInternalMethodNode.java>CallInternalMethodNode</a>, separating the mechanisms responsible for retrieving a method on a class and calling it, respectively.</p>
<p>Here is what this part of the AST &ldquo;looks&rdquo; like:
<img src=NodeHierarchy.svg alt></p>
<p>Let’s explore <code>LookupMethodNode</code> first:</p>
<pre tabindex=0><code>class LookupMethodNode

    cache :meta_class, :name
    cache &quot;lookup_method(cached_meta_class, cached_name)&quot;, as: :method_lookup_result
    limit :get_cache_limit
    guard_on :cached_meta_class, :cached_name
    def lookup_method_cached(meta_class, name)
        return method_lookup_result
    end
end
</code></pre><p>Simplified from:</p>
<pre tabindex=0><code>@Specialization(
        guards = {
                &quot;isSingleContext()&quot;,
                &quot;metaClass == cachedMetaClass&quot;,
                &quot;name == cachedName&quot;,
                &quot;config == cachedConfig&quot; },
        assumptions = &quot;methodLookupResult.getAssumptions()&quot;,
        limit = &quot;getCacheLimit()&quot;)
protected InternalMethod lookupMethodCached(
        Frame frame, RubyClass metaClass, String name, DispatchConfiguration config,
        @Cached(&quot;metaClass&quot;) RubyClass cachedMetaClass,
        @Cached(&quot;name&quot;) String cachedName,
        @Cached(&quot;config&quot;) DispatchConfiguration cachedConfig,
        @Cached(&quot;lookupCached(getContext(), frame, cachedMetaClass, cachedName, config)&quot;) MethodLookupResult methodLookupResult) {

    return methodLookupResult.getMethod();
}
</code></pre><p>We&rsquo;ve encountered our first generalized PIC in the dispatch chain! Caching on the <code>metaClass</code> (essentially the class of the object) and the <code>name</code> of the method being passed in, this node takes a Ruby class and method name to look up, and pops out an <code>InternalMethod</code> object. Note that this stores up to <code>getCacheLimit()</code> entries, which is why it is a <em>poly</em> morphic cache.</p>
<p>Next, let&rsquo;s examine <code>CallInternalMethodNode</code>, which is passed the lookup node’s <code>InternalMethod</code> result:</p>
<pre tabindex=0><code>final InternalMethod method = lookupMethodNode.execute(frame, metaclass, methodName, config);

/*
 * Cut out implementationdetails
 */

return callNode.execute(frame, method, receiver, rubyArgs, literalCallNode);
</code></pre><p>Simplified once again:</p>
<pre tabindex=0><code>class CallInternalMethodNode

    cache :method
    cache &quot;method.get_call_target&quot;, as: :call_target
    cache &quot;create_call(cached_method.get_name, cached_call_target)&quot;, as: :call_node
    guard_on :cached_call_target, &quot;!cached_method.always_inlined?&quot;
    limit :get_cache_limit
    def call_cached(method, *method_args)
        # Note how the call node is generated and cached as part of the cache entry from a cached method and cached call target.
        # As long as the guards are not violated, all of this is stored in the poly cache and invoked speedily.
        call_node.call(call_target, method_args)
    end
end
</code></pre><p>From:</p>
<pre tabindex=0><code>@Specialization(
        guards = {
                &quot;isSingleContext()&quot;,
                &quot;method.getCallTarget() == cachedCallTarget&quot;,
                &quot;!cachedMethod.alwaysInlined()&quot; },
        assumptions = &quot;getMethodAssumption(cachedMethod)&quot;, // to remove the inline cache entry when the method is redefined or removed
        limit = &quot;getCacheLimit()&quot;)
protected Object callCached(
        InternalMethod method, Object receiver, Object[] rubyArgs, LiteralCallNode literalCallNode,
        @Cached(&quot;method.getCallTarget()&quot;) RootCallTarget cachedCallTarget,
        @Cached(&quot;method&quot;) InternalMethod cachedMethod,
        @Cached(&quot;createCall(cachedMethod.getName(), cachedCallTarget)&quot;) DirectCallNode callNode) {
    if (literalCallNode != null) {
        literalCallNode.copyRuby2KeywordsHash(rubyArgs, cachedMethod.getSharedMethodInfo());
    }

    return callNode.call(RubyArguments.repackForCall(rubyArgs));
}
</code></pre><p>As a result, we&rsquo;re able to sequence these PICs so that the processes of converting a call site to a method lookup and the method execution are cached separately & based on unique properties relevant to the data flow at each process.</p>
<h2 id=what-can-we-take-away-from-it-all>What can we take away from it all?</h2>
<p>TruffleRuby uses this advanced and complex/compound design of inline caching because it tackles some of the dynamic nature of Ruby. For example, complex class hierarchies methods that are aliased with different names can result in a call to the same code, and our technique means we can de-duplicate that call and ensure speedy execution of interpreted <em>and</em> JITted code.</p>
<p>Currently, we&rsquo;re using these techniques to optimise conventional Ruby and especially metaprogramming in powerful ways. We think we can use their power and flexibility to address other Ruby idioms that aren&rsquo;t currently well-optimised, such as extensive use of singletons to define per-object methods. At the moment these trip up the VM as they cause the first layer of caching to become megamorphic. Our ongoing work is looking at adding another level of indirection and further specializing on top of the dispatch system to accommodate for singleton classes, ensuring that idiomatic & expressive Ruby continues to be performant.</p>
<h2 id=special-thanks>Special Thanks</h2>
<p>Thanks to <a href=https://chrisseaton.com/>Chris Seaton</a>, <a href=https://nirvdrum.com/>Kevin Menard</a>, <a href=https://kddnewton.com/>Kevin Newton</a>, and <a href=https://twitter.com/Kaan0zkan>Kaan Ozkan</a> for looking over and providing feedback on early drafts of mine, and to <a href=https://tenderlovemaking.com/>Aaron Patterson</a> for the MRI caching crash course.</p>
</div>
</div>
</div>
</div>
</div>
<section id=comments>
<div class="py-3 content">
<div class=container>
<div class="row justify-content-center">
<div class="col-sm-12 col-lg-8">
<div class=comments>
<script src=https://utteranc.es/client.js repo issue-term=pathname label=comment theme=github-light crossorigin=anonymous async></script>
</div>
</div>
</div>
</div>
</div>
</section>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/java.min.js defer></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js defer></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/ruby.min.js defer></script>
<script>window.addEventListener('load',function(){hljs.initHighlighting()},!0)</script>
</body>
</html>